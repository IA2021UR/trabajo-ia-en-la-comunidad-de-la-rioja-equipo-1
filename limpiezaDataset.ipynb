{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "limpiezaDataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzn8Q0TnMI/xQsr8Ouy9ln",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IA2021UR/trabajo-ia-en-la-comunidad-de-la-rioja-equipo-1/blob/main/limpiezaDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXod-rG-GUQ0"
      },
      "source": [
        "El dataset propuesto contiene aproximadamente 21.000 imágenes para lograr una mayor rapidez en la limpieza de los datos comenzaremos limpiando el dataset de imágenes que no tengan caras, este es el objetivo principal de este cuaderno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVByOl2iGu7R"
      },
      "source": [
        "# 1.Descarga del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZs1qeNWGIwm"
      },
      "source": [
        "!wget https://www.dropbox.com/s/icj8g7cu3krttge/2.zip?dl=0 -O data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT31tWLeG2av"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhxMBis8Gzaq"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBbp_HiwHgid",
        "outputId": "1344747f-a1f2-462d-f1bc-5a1f9fd0ff4a"
      },
      "source": [
        "# Leer primer modelo de red convolucional\n",
        "!wget https://www.dropbox.com/s/uji1ufb009ic3m0/mobilenet_graph.pb?dl=0 -O mobilenet_graph.pb\n",
        "\n",
        "with tf.io.gfile.GFile('mobilenet_graph.pb','rb') as f:\n",
        "    graph_def = tf.compat.v1.GraphDef()\n",
        "    graph_def.ParseFromString(f.read())\n",
        "\n",
        "with tf.Graph().as_default() as mobilenet:\n",
        "    tf.import_graph_def(graph_def,name='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-15 09:59:36--  https://www.dropbox.com/s/uji1ufb009ic3m0/mobilenet_graph.pb?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/uji1ufb009ic3m0/mobilenet_graph.pb [following]\n",
            "--2021-05-15 09:59:36--  https://www.dropbox.com/s/raw/uji1ufb009ic3m0/mobilenet_graph.pb\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc43fc07b3ce32cb78581e4a8fc5.dl.dropboxusercontent.com/cd/0/inline/BOixmWbGeZ8N0l04fTd6XaQAqtZxHlt8C4RRnW3GcqPOse-Tx1zQaePKkN6N7DV70Oz_LKaIO4Oa1hgK2sTfZxE1OF60-3WfjuvLfGekM3fa1_DzsttBUMS3Ch4W6UpuAJjUv9NMeOjI-UN5vVidRtmY/file# [following]\n",
            "--2021-05-15 09:59:36--  https://uc43fc07b3ce32cb78581e4a8fc5.dl.dropboxusercontent.com/cd/0/inline/BOixmWbGeZ8N0l04fTd6XaQAqtZxHlt8C4RRnW3GcqPOse-Tx1zQaePKkN6N7DV70Oz_LKaIO4Oa1hgK2sTfZxE1OF60-3WfjuvLfGekM3fa1_DzsttBUMS3Ch4W6UpuAJjUv9NMeOjI-UN5vVidRtmY/file\n",
            "Resolving uc43fc07b3ce32cb78581e4a8fc5.dl.dropboxusercontent.com (uc43fc07b3ce32cb78581e4a8fc5.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc43fc07b3ce32cb78581e4a8fc5.dl.dropboxusercontent.com (uc43fc07b3ce32cb78581e4a8fc5.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BOgLcuXZMRDB35IqIujYTb12NjEhk4x1AGkDPHn4M4-uTq50lELhkMffx7G0ZmoCaWttMZqjZEwIK3QJn30YG0YlL6r65NDowjAX7286eSCh7dDP-eTrDHDRv213VwGUv_G7VTamC_2zX_igehRndI_6LpZ-2qjVudHT22XjmFZNuOr2b4sJRz_V4NtUzzJEVIZ-0dlO23aZOnTnGoUlSxi3V51AZCLVBF9ItAZAFekXhOmcfP7nbwd9csbx0tF0EDBMZDEhVhpFFP1g4ifi8gZY-sY-jtulkx2RvKyIZy9SE_1iI953xOsk1QI1KqYkANv4B0HpL6CTu6NNmoHgfzXJq3OkMtoCOie76zB8bUexMdOo_ZGn6i69QzEKLsp8Eiw/file [following]\n",
            "--2021-05-15 09:59:36--  https://uc43fc07b3ce32cb78581e4a8fc5.dl.dropboxusercontent.com/cd/0/inline2/BOgLcuXZMRDB35IqIujYTb12NjEhk4x1AGkDPHn4M4-uTq50lELhkMffx7G0ZmoCaWttMZqjZEwIK3QJn30YG0YlL6r65NDowjAX7286eSCh7dDP-eTrDHDRv213VwGUv_G7VTamC_2zX_igehRndI_6LpZ-2qjVudHT22XjmFZNuOr2b4sJRz_V4NtUzzJEVIZ-0dlO23aZOnTnGoUlSxi3V51AZCLVBF9ItAZAFekXhOmcfP7nbwd9csbx0tF0EDBMZDEhVhpFFP1g4ifi8gZY-sY-jtulkx2RvKyIZy9SE_1iI953xOsk1QI1KqYkANv4B0HpL6CTu6NNmoHgfzXJq3OkMtoCOie76zB8bUexMdOo_ZGn6i69QzEKLsp8Eiw/file\n",
            "Reusing existing connection to uc43fc07b3ce32cb78581e4a8fc5.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22684355 (22M) [application/octet-stream]\n",
            "Saving to: ‘mobilenet_graph.pb’\n",
            "\n",
            "mobilenet_graph.pb  100%[===================>]  21.63M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-05-15 09:59:37 (182 MB/s) - ‘mobilenet_graph.pb’ saved [22684355/22684355]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdRLRY3jHqAO"
      },
      "source": [
        "# Cargar imagen\n",
        "def load_image(DIR, NAME):\n",
        "    return cv2.cvtColor(cv2.imread(f'{DIR}/{name}'), cv2.COLOR_BGR2RGB)\n",
        "def detect_faces(image, score_threshold=0.7):\n",
        "    global boxes, scores\n",
        "    (imh, imw) = image.shape[:-1]\n",
        "    img = np.expand_dims(image,axis=0)\n",
        "    \n",
        "    # Inicializar mobilenet\n",
        "    sess = tf.compat.v1.Session(graph=mobilenet)\n",
        "    image_tensor = mobilenet.get_tensor_by_name('image_tensor:0')\n",
        "    boxes = mobilenet.get_tensor_by_name('detection_boxes:0')\n",
        "    scores = mobilenet.get_tensor_by_name('detection_scores:0')\n",
        "    \n",
        "    # Predicción (detección)\n",
        "    (boxes, scores) = sess.run([boxes, scores], feed_dict={image_tensor:img})\n",
        "    \n",
        "    # Reajustar tamaños boxes, scores\n",
        "    boxes = np.squeeze(boxes,axis=0)\n",
        "    scores = np.squeeze(scores,axis=0)\n",
        "    \n",
        "    # Depurar bounding boxes\n",
        "    idx = np.where(scores>=score_threshold)[0]\n",
        "    \n",
        "    # Crear bounding boxes\n",
        "    bboxes = []\n",
        "    for index in idx:\n",
        "        ymin, xmin, ymax, xmax = boxes[index,:]\n",
        "        (left, right, top, bottom) = (xmin*imw, xmax*imw, ymin*imh, ymax*imh)\n",
        "        left, right, top, bottom = int(left), int(right), int(top), int(bottom)\n",
        "        bboxes.append([left,right,top,bottom])\n",
        "        \n",
        "    return bboxes\n",
        "# Extraer rostros\n",
        "def extract_faces(image,bboxes,new_size=(160,160)):\n",
        "    cropped_faces = []\n",
        "    for box in bboxes:\n",
        "        left, right, top, bottom = box\n",
        "        face = image[top:bottom,left:right]\n",
        "        cropped_faces.append(cv2.resize(face,dsize=new_size))\n",
        "    return cropped_faces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hfsZBWpIpd8"
      },
      "source": [
        "A partir de estas imágenes obtendremos solo aquellas que tengan cara, para optimizar los resultados estableceremos un tamaño de imagen para todas imágenes de nuestro dataset, esto nos permitirá encontrar aquellas caras más similares en pasos posteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0RfPr0KLo1w"
      },
      "source": [
        "from os import remove\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxYupoVcMkuE",
        "outputId": "7ebb9ec7-b9cf-4929-94fa-1dc7a06293df"
      },
      "source": [
        "print('imagenes originales:'+ str(len(os.listdir('2'))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imagenes originales:21609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn8TYy4fY5sr"
      },
      "source": [
        "Primero eliminamos las imágenes que producen errores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRHq9CJlK6TK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5496fb8-a1d4-4199-aa29-70e71caacb1c"
      },
      "source": [
        "directorio='2'\n",
        "for name in os.listdir('2'):\n",
        "      try:\n",
        "          image= cv2.cvtColor(cv2.imread(f'{directorio}/{name}'), cv2.COLOR_BGR2RGB)   \n",
        "      except:\n",
        "          print('Error , la imagen es defectuosa: ' + name )\n",
        "          remove('2/'+name) \n",
        "          \n",
        "print('fin')         \n",
        "      \n",
        "            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hsrXeiz_X0S"
      },
      "source": [
        "Hemos eliminado unas 70 imágenes defectuosas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEX-oLKGewHA"
      },
      "source": [
        "Nota: este proceso es muy costoso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-7sbB9NZNc7"
      },
      "source": [
        "directorio='2'\n",
        "num=len(os.listdir('2'))\n",
        "\n",
        "for name in range (0,num):\n",
        "          image= cv2.cvtColor(cv2.imread(directorio+'/'+os.listdir('2')[name]), cv2.COLOR_BGR2RGB)\n",
        "          bboxes = detect_faces(image)\n",
        "          if len(bboxes)==0:\n",
        "            print(f'{name}'+ ':' + str(num))\n",
        "            num=num-1\n",
        "            remove('2'+'/'+str(os.listdir('2')[name]))     \n",
        "\n",
        "print('fin')         \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DeQis-hTz3Y",
        "outputId": "bc17230b-b381-418e-ab70-c4fa75777a75"
      },
      "source": [
        "print('imagenes que contienen caras:'+ str(len(os.listdir('2'))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imagenes que contienen caras:19021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMemWp9WVyZ"
      },
      "source": [
        "Ahora zipeamos el nuevo dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EWPaNALUPRs"
      },
      "source": [
        "!zip -r ./3.zip ./2/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkUraCPpamN9"
      },
      "source": [
        "Ahora que hemos eliminado unas ** 2500**, es decir hemos limpiado un 10% imágenes que no íbamos a utilizar.\n",
        "Ahora procedemos a la segunda mejora del dataset, en este caso crearemos el nuevo dataset que estará formado sólamente por caras y permitirá obtener búsquedas más exactas de la cara de una persona."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGsEU6jb-Ki"
      },
      "source": [
        "Ahora descargamos este resultado que guardamos en dropbox por comodidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnNQOVPTpDsr"
      },
      "source": [
        "**Nota** He borrado este dataset porque no quedaba espacio en el dropbox,lo he sustituido por este que he obtenido, este será el dataset que utilizaremos en el resto de cuadernos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jweem4H7b85m"
      },
      "source": [
        "!wget https://www.dropbox.com/s/knkdotwfob09y2u/3.zip?dl=0 -O 3.zip\n",
        "!unzip 3.zip"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}